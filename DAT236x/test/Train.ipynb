{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Train on 34000 samples, validate on 6000 samples\n",
      "Epoch 1/20\n",
      "34000/34000 [==============================] - 36s 1ms/step - loss: 0.4312 - acc: 0.8414 - val_loss: 0.0223 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.43120, saving model to model.h5\n",
      "Epoch 2/20\n",
      "34000/34000 [==============================] - 33s 973us/step - loss: 0.0231 - acc: 0.9934 - val_loss: 0.0062 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00002: loss improved from 0.43120 to 0.02311, saving model to model.h5\n",
      "Epoch 3/20\n",
      "34000/34000 [==============================] - 33s 975us/step - loss: 0.0104 - acc: 0.9971 - val_loss: 0.0072 - val_acc: 0.9982\n",
      "\n",
      "Epoch 00003: loss improved from 0.02311 to 0.01039, saving model to model.h5\n",
      "Epoch 4/20\n",
      "34000/34000 [==============================] - 33s 975us/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0068 - val_acc: 0.9985\n",
      "\n",
      "Epoch 00004: loss improved from 0.01039 to 0.00649, saving model to model.h5\n",
      "Epoch 5/20\n",
      "34000/34000 [==============================] - 33s 978us/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0052 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00005: loss improved from 0.00649 to 0.00432, saving model to model.h5\n",
      "Epoch 6/20\n",
      "34000/34000 [==============================] - 33s 975us/step - loss: 0.0055 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9995\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.00432\n",
      "Epoch 7/20\n",
      "34000/34000 [==============================] - 33s 974us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0096 - val_acc: 0.9978\n",
      "\n",
      "Epoch 00007: loss improved from 0.00432 to 0.00295, saving model to model.h5\n",
      "Epoch 8/20\n",
      "34000/34000 [==============================] - 33s 974us/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0052 - val_acc: 0.9993\n",
      "\n",
      "Epoch 00008: loss improved from 0.00295 to 0.00275, saving model to model.h5\n",
      "Epoch 9/20\n",
      "34000/34000 [==============================] - 33s 974us/step - loss: 0.0018 - acc: 0.9993 - val_loss: 0.0058 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00009: loss improved from 0.00275 to 0.00180, saving model to model.h5\n",
      "Epoch 10/20\n",
      "34000/34000 [==============================] - 33s 974us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0050 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.00180\n",
      "Epoch 11/20\n",
      "34000/34000 [==============================] - 33s 972us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00011: loss improved from 0.00180 to 0.00122, saving model to model.h5\n",
      "Epoch 12/20\n",
      "34000/34000 [==============================] - 33s 971us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0048 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.00122\n",
      "Epoch 13/20\n",
      "34000/34000 [==============================] - 33s 974us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0060 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.00122\n",
      "Epoch 14/20\n",
      "34000/34000 [==============================] - 33s 973us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0065 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00014: loss improved from 0.00122 to 0.00103, saving model to model.h5\n",
      "Epoch 15/20\n",
      "34000/34000 [==============================] - 33s 972us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.00103\n",
      "Epoch 16/20\n",
      "34000/34000 [==============================] - 33s 971us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.00103\n",
      "Epoch 17/20\n",
      "34000/34000 [==============================] - 33s 971us/step - loss: 0.0010 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.00103\n",
      "Epoch 18/20\n",
      "34000/34000 [==============================] - 33s 972us/step - loss: 5.6863e-04 - acc: 0.9998 - val_loss: 0.0069 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00018: loss improved from 0.00103 to 0.00057, saving model to model.h5\n",
      "Epoch 19/20\n",
      "34000/34000 [==============================] - 33s 971us/step - loss: 7.7842e-04 - acc: 0.9998 - val_loss: 0.0069 - val_acc: 0.9990\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.00057\n",
      "Epoch 20/20\n",
      "34000/34000 [==============================] - 33s 969us/step - loss: 7.1528e-04 - acc: 0.9998 - val_loss: 0.0092 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.00057\n",
      "Test loss: 0.00921940774990469\n",
      "Test accuracy: 0.9991666666666666\n",
      "Wall time: 11min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np \n",
    "import keras \n",
    "import keras \n",
    "from keras.preprocessing.image import img_to_array \n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.models import Sequential, load_model \n",
    "from keras.layers import Dense, Dropout, Flatten \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from imutils import paths \n",
    "import random \n",
    "import pickle \n",
    "import cv2 \n",
    "import os\n",
    "\n",
    "BatchSize = 128\n",
    "Classes = 4 \n",
    "Epochs = 20 \n",
    "InputShape = (64, 64, 3) \n",
    "data = [] \n",
    "labels = []\n",
    "\n",
    "print(\"Loading training data...\") \n",
    "imagePaths = sorted(list(paths.list_images('C:/Training/Capstone/train/'))) \n",
    "random.seed(42) \n",
    "random.shuffle(imagePaths) \n",
    "\n",
    "# loop over the input images \n",
    "for imagePath in imagePaths: \n",
    "    image = cv2.imread(imagePath, cv2.COLOR_RGB2GRAY) \n",
    "    image = img_to_array(image) \n",
    "    data.append(image) \n",
    "    label = imagePath.split(os.path.sep)[-2].split(\"_\")[0] \n",
    "    # train images are spread across four folders based on their classes \n",
    "    if 'ZERO' in label: \n",
    "        labels.append('ZERO') \n",
    "    if 'ONE' in label: \n",
    "        labels.append('ONE') \n",
    "    if 'TWO' in label: \n",
    "        labels.append('TWO') \n",
    "    if 'THREE' in label: \n",
    "        labels.append('THREE') \n",
    "\n",
    "# scale the raw pixel intensities to the range [0, 1] \n",
    "data = np.array(data, dtype=\"float\") / 255.0 \n",
    "labels = np.array(labels) \n",
    "\n",
    "# binarize the labels \n",
    "mlb = LabelBinarizer() \n",
    "labels = mlb.fit_transform(labels) \n",
    "\n",
    "# partition the data into training and test splits (85/15) \n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data, labels, test_size=0.15, random_state=42) \n",
    "\n",
    "# construct our model \n",
    "model = Sequential() \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=InputShape)) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25)) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(128, activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(Classes, activation='softmax')) \n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy, \n",
    "              optimizer=keras.optimizers.Adadelta(), \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "filepath = \"model.h5\" \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min') \n",
    "callbacks_list = [checkpoint] \n",
    "\n",
    "# start training \n",
    "model.fit(x_train, y_train, batch_size=BatchSize, epochs=Epochs, verbose=1, \n",
    "          validation_data=(x_test, y_test), callbacks=callbacks_list) \n",
    "score = model.evaluate(x_test, y_test, verbose=0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 411 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save the model and multi-label binarizer to disk so we can classify our submission later \n",
    "model.save('capstone.model') \n",
    "f = open('capstone.pickle', \"wb\") \n",
    "f.write(pickle.dumps(mlb)) \n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
